OpenPolit 是一套用于驾驶辅助和自动驾驶的开放源代码模型，其中包括三个核心模型：SuperCombo、Nav 和 Driver Monitoring。以下是它们的详细介绍及输入输出参数。

1. SuperCombo
SuperCombo 是一个多任务深度学习模型，结合了多个驾驶任务的预测和控制，主要用于车辆的驾驶决策和行为预测。它能够处理驾驶场景中的多种任务，如车道保持、前车跟踪、交通信号识别等。

输入参数：
图像数据：前置摄像头捕获的图像，通常是 RGB 图像（大小为 224x224 或更高分辨率）。
车辆状态：车辆的速度、加速度、方向盘角度等。
传感器数据：来自激光雷达（LiDAR）或雷达的数据。
地图数据：高清地图或道路网络信息，用于路线规划。
输出：
车道保持控制信号：指示是否需要调整方向盘。
前车跟踪指令：根据前车位置和速度，计算跟车的加速度和制动信号。
交通标志识别：识别并返回检测到的交通标志信息（如限速标志、停车标志等）。
行驶方向指令：在特定场景下给出车辆应该采取的行动（如转向、停车、变道等）。
2. Nav (Navigation)
Nav 模型负责处理车辆的导航任务，主要是基于车辆的当前位置信息和目的地进行路径规划和实时导航。

输入参数：
当前位置：车辆的 GPS 坐标（经度、纬度）。
目标位置：目的地的 GPS 坐标。
路况数据：实时交通信息，包括道路交通堵塞情况、施工区、交通事故等。
地图数据：高清地图，包含道路网络、路口信息等。
车辆状态：当前的车速、加速度、行驶方向等信息。
输出：
最佳路径规划：推荐的行驶路线，可以是多条备选路径。
路线细节：例如路段的距离、预计行驶时间、导航指示（如“前方左转”）。
实时交通更新：基于实时交通数据，动态调整路径，避免交通拥堵区域。
3. Driver Monitoring
Driver Monitoring 模型专注于监测驾驶员的状态和行为，特别是疲劳驾驶和注意力分散的检测。通过分析驾驶员的面部表情、头部姿态和眼睛运动等信息，评估驾驶员的警觉性。

输入参数：
驾驶员图像数据：通过内置摄像头获取的驾驶员面部图像或视频流。
驾驶员姿态信息：头部的位置和运动数据。
眼动跟踪数据：通过摄像头监测驾驶员的眼睛位置和眨眼频率。
生理数据：例如心率、皮肤电反应等（如有传感器支持）。
输出：
疲劳警告：如果检测到驾驶员出现疲劳迹象（如长时间无眨眼、头部倾斜等），则输出警告信息。
注意力分散警告：如果驾驶员视线偏离前方道路太久（如看手机、外界环境等），则触发警告。
驾驶员状态评分：综合评估驾驶员的警觉性和集中度，给出评分或警告等级。
这些模型通过深度学习算法对车辆的周围环境、驾驶员行为及车辆自身状态进行智能处理，帮助提升驾驶安全性和自动化水平。
