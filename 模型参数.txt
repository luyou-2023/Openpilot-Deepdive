OpenPolit 是一套用于驾驶辅助和自动驾驶的开放源代码模型，其中包括三个核心模型：SuperCombo、Nav 和 Driver Monitoring。以下是它们的详细介绍及输入输出参数。

1. SuperCombo
SuperCombo 是一个多任务深度学习模型，结合了多个驾驶任务的预测和控制，主要用于车辆的驾驶决策和行为预测。它能够处理驾驶场景中的多种任务，如车道保持、前车跟踪、交通信号识别等。

输入参数：
图像数据：前置摄像头捕获的图像，通常是 RGB 图像（大小为 224x224 或更高分辨率）。
车辆状态：车辆的速度、加速度、方向盘角度等。
传感器数据：来自激光雷达（LiDAR）或雷达的数据。
地图数据：高清地图或道路网络信息，用于路线规划。
输出：
车道保持控制信号：指示是否需要调整方向盘。
前车跟踪指令：根据前车位置和速度，计算跟车的加速度和制动信号。
交通标志识别：识别并返回检测到的交通标志信息（如限速标志、停车标志等）。
行驶方向指令：在特定场景下给出车辆应该采取的行动（如转向、停车、变道等）。
2. Nav (Navigation)
Nav 模型负责处理车辆的导航任务，主要是基于车辆的当前位置信息和目的地进行路径规划和实时导航。

输入参数：
当前位置：车辆的 GPS 坐标（经度、纬度）。
目标位置：目的地的 GPS 坐标。
路况数据：实时交通信息，包括道路交通堵塞情况、施工区、交通事故等。
地图数据：高清地图，包含道路网络、路口信息等。
车辆状态：当前的车速、加速度、行驶方向等信息。
输出：
最佳路径规划：推荐的行驶路线，可以是多条备选路径。
路线细节：例如路段的距离、预计行驶时间、导航指示（如“前方左转”）。
实时交通更新：基于实时交通数据，动态调整路径，避免交通拥堵区域。
3. Driver Monitoring
Driver Monitoring 模型专注于监测驾驶员的状态和行为，特别是疲劳驾驶和注意力分散的检测。通过分析驾驶员的面部表情、头部姿态和眼睛运动等信息，评估驾驶员的警觉性。

输入参数：
驾驶员图像数据：通过内置摄像头获取的驾驶员面部图像或视频流。
驾驶员姿态信息：头部的位置和运动数据。
眼动跟踪数据：通过摄像头监测驾驶员的眼睛位置和眨眼频率。
生理数据：例如心率、皮肤电反应等（如有传感器支持）。
输出：
疲劳警告：如果检测到驾驶员出现疲劳迹象（如长时间无眨眼、头部倾斜等），则输出警告信息。
注意力分散警告：如果驾驶员视线偏离前方道路太久（如看手机、外界环境等），则触发警告。
驾驶员状态评分：综合评估驾驶员的警觉性和集中度，给出评分或警告等级。
这些模型通过深度学习算法对车辆的周围环境、驾驶员行为及车辆自身状态进行智能处理，帮助提升驾驶安全性和自动化水平。


supercombo模型输出
struct ModelOutput {
  const ModelOutputPlans plans;                                    #size: 4955
  const ModelOutputLaneLines lane_lines;                           #size: 528 + 8
  const ModelOutputRoadEdges road_edges;                           #size: 264
  const ModelOutputLeads leads;                                    #size: 102 + 3
  const ModelOutputMeta meta;                                      #size: 8 + 48 + 32
  const ModelOutputPose pose;                                      #size: 12
  const ModelOutputWideFromDeviceEuler wide_from_device_euler;     #size: 6
  const ModelOutputTemporalPose temporal_pose;                     #size: 12

  ##下面这是struct中未定义的，但实际有的
  const float feature[128];                                        #size: 128
};


ModelOutputPlans的定义如下：
const int TRAJECTORY_SIZE = 33;
constexpr int PLAN_MHP_N = 5;

struct ModelOutputXYZ {
  float x;
  float y;
  float z;
};
#size: 3

struct ModelOutputPlanElement {
  ModelOutputXYZ position;
  ModelOutputXYZ velocity;
  ModelOutputXYZ acceleration;
  ModelOutputXYZ rotation;
  ModelOutputXYZ rotation_rate;
};
#size: 15

struct ModelOutputPlanPrediction {
  std::array<ModelOutputPlanElement, TRAJECTORY_SIZE> mean;
  std::array<ModelOutputPlanElement, TRAJECTORY_SIZE> std;
  float prob;
};
#size: 15*33 + 15*33 + 1 = 991

struct ModelOutputPlans {
  std::array<ModelOutputPlanPrediction, PLAN_MHP_N> prediction;
}
#size: 991 * 5 = 4955

在 SuperCombo 模型的输出中，ModelOutput 是主要的输出结构，它包含了多个子结构，每个子结构都代表了模型在不同方面的预测结果。让我们逐一分析这些子结构以及它们的参数。

1. ModelOutputPlans
这个结构包含了多个计划预测，每个计划代表模型对不同轨迹的预测。ModelOutputPlans 的大小是 4955，它由多个 ModelOutputPlanPrediction 组成，每个 ModelOutputPlanPrediction 进一步包含了多个轨迹点的预测。

相关结构：
ModelOutputPlanElement
每个轨迹点由以下数据组成：

position: 坐标位置（x, y, z）
velocity: 速度（x, y, z）
acceleration: 加速度（x, y, z）
rotation: 旋转（x, y, z）
rotation_rate: 旋转速率（x, y, z）
每个 ModelOutputPlanElement 的大小是 15。

ModelOutputPlanPrediction
每个计划预测包含了 TRAJECTORY_SIZE 个轨迹点的预测结果（在代码中为 33 个点）。这些点分别有 mean（均值）和 std（标准差）两组数据。

mean 和 std 都是一个大小为 15 的 ModelOutputPlanElement 数组，共 33 个元素。
prob: 预测的概率（float 类型）。
ModelOutputPlanPrediction 的总大小是 991（33个轨迹点 × 15 + 33个轨迹点 × 15 + 1个概率）。

ModelOutputPlans
这个结构包含了 PLAN_MHP_N（5）的 ModelOutputPlanPrediction 元素，表示模型对 5 条不同计划轨迹的预测。

总大小是 4955（991 × 5）。
2. ModelOutputLaneLines
这个结构包含了与车道线相关的预测数据。它的大小是 528 + 8。

车道线通常是基于图像处理和环境感知进行预测的，可能包含多个车道线的位置、曲率和其他属性。
3. ModelOutputRoadEdges
这个结构包含了与道路边缘相关的数据，大小为 264。

通常用于表示道路的边缘位置和形态，帮助车辆识别道路的边界。
4. ModelOutputLeads
这个结构包含了与前方车辆（或障碍物）相关的信息，大小为 102 + 3。

包括前方车辆的位置、速度、加速度、角度等信息。
5. ModelOutputMeta
这个结构包含了模型的元数据，大小为 8 + 48 + 32。

可能包括一些模型的配置信息、时间戳、或其他辅助数据。
6. ModelOutputPose
这个结构包含了与车辆姿态相关的数据，大小为 12。

可能表示车辆的位置信息、旋转信息等（如车身姿态、方向等）。
7. ModelOutputWideFromDeviceEuler
这个结构包含了从设备传感器（如IMU或其他设备）获得的欧拉角信息，大小为 6。

用于表示传感器的方向和旋转（通常是姿态数据）。
8. ModelOutputTemporalPose
这个结构包含了与时间相关的姿态数据，大小为 12。

可能表示随时间变化的姿态数据，用于分析动态变化的运动状态。
9. feature
这是一个大小为 128 的浮动数组，包含了模型提取的特征数据。

这些特征可能是从图像数据、传感器数据、或其他输入中提取的，用于进一步的决策或行为预测。
总结：
ModelOutput 是一个包含多个重要预测和状态信息的结构，用于描述 SuperCombo 模型的输出结果。各个子结构代表了不同方面的预测，如轨迹规划、车道线、道路边缘、前方车辆信息等，同时还包括一些辅助的元数据和特征数据。通过这些输出，模型可以根据环境数据作出决策并提供控制指令。



ModelOutputLaneLines的定义如下：
const int TRAJECTORY_SIZE = 33;

struct ModelOutputYZ {
  float y;
  float z;
};
#size: 2

struct ModelOutputLinesXY {
  std::array<ModelOutputYZ, TRAJECTORY_SIZE> left_far;
  std::array<ModelOutputYZ, TRAJECTORY_SIZE> left_near;
  std::array<ModelOutputYZ, TRAJECTORY_SIZE> right_near;
  std::array<ModelOutputYZ, TRAJECTORY_SIZE> right_far;
};
#size: 2 * 33 * 4 = 264

struct ModelOutputLineProbVal {
  float val_deprecated;
  float val;
};
#size: 2

struct ModelOutputLinesProb {
  ModelOutputLineProbVal left_far;
  ModelOutputLineProbVal left_near;
  ModelOutputLineProbVal right_near;
  ModelOutputLineProbVal right_far;
};
#size: 8

struct ModelOutputLaneLines {
  ModelOutputLinesXY mean;
  ModelOutputLinesXY std;
  ModelOutputLinesProb prob;
};
#size: 264 + 264 + 8 = 528 + 8 这里分开写，是因为onnx里这里是2个输出的concat
总结一下supercombo模型输出的ModelOutputLaneLines，其包含4段车道线，分别是left_far，left_near，right_near，right_far，每条车道线有33个2D坐标系的点和一个置信度ProbVal，每个点分别有mean和std。


ModelOutputLaneLines 解析
ModelOutputLaneLines 是 SuperCombo 模型输出的一个重要部分，专注于预测车道线的位置和置信度。它的输出涉及四段车道线：left_far、left_near、right_near 和 right_far，每一段车道线包含了若干个点的位置、标准差和置信度。下面对该结构进行详细解释：

定义解析：
1. ModelOutputYZ
ModelOutputYZ 表示每个车道线点的二维坐标，包含两个分量：y 和 z，即车道线在 y-z 平面上的位置。

大小: 2（y 和 z 两个分量）。
2. ModelOutputLinesXY
ModelOutputLinesXY 表示四条车道线在二维坐标系中的位置，它包含了四个数组，每个数组包含 33 个 ModelOutputYZ 类型的点（每个点由 y 和 z 坐标组成）。

left_far: 远离车辆的左侧车道线。
left_near: 靠近车辆的左侧车道线。
right_near: 靠近车辆的右侧车道线。
right_far: 远离车辆的右侧车道线。
每条车道线有 33 个点，因此每条车道线包含了 33 × 2 个数据（即 y 和 z 坐标）。

大小: 264（2 × 33 × 4）。
3. ModelOutputLineProbVal
ModelOutputLineProbVal 结构包含了每条车道线的置信度信息，包括一个过时的值 val_deprecated 和当前有效的置信度值 val。

大小: 2（包含 val_deprecated 和 val 两个浮点值）。
4. ModelOutputLinesProb
ModelOutputLinesProb 包含了四条车道线的置信度值，分别是 left_far、left_near、right_near 和 right_far。

每条车道线的置信度包含一个 ModelOutputLineProbVal 结构。
大小: 8（每条车道线一个 ModelOutputLineProbVal，总共四条车道线）。
5. ModelOutputLaneLines
ModelOutputLaneLines 结构包含了车道线的均值（mean）、标准差（std）和置信度（prob）信息。

mean: 车道线的均值，表示车道线位置的预测值。
std: 车道线的标准差，表示车道线位置的置信度的离散程度。
prob: 车道线的置信度值。
具体来说：

mean 和 std 都是 ModelOutputLinesXY 结构，表示每条车道线的均值和标准差（每条车道线有 33 个点）。
prob 是 ModelOutputLinesProb 结构，包含每条车道线的置信度值。
大小：

mean 和 std: 每个是 264（2 × 33 × 4）。
prob: 8。
因此，ModelOutputLaneLines 总大小是：

528 + 8（mean 和 std 各 264，prob 为 8）。
总结：
ModelOutputLaneLines 包含了四段车道线的预测，每段车道线有 33 个点，每个点由 y 和 z 坐标组成。此外，对于每条车道线，还包括其预测的均值（mean）、标准差（std）和置信度（prob）。这些信息帮助模型精确描述车道线的位置和不确定性，用于自动驾驶中车道保持和路径规划等任务。

具体来说：

每条车道线的 33 个点 的位置（y, z 坐标）通过 mean 和 std 来表示。
每条车道线的 置信度 通过 prob 提供，其中包括了一个有效的置信度值 val。


ModelOutputRoadEdges的定义如下：
const int TRAJECTORY_SIZE = 33;

struct ModelOutputYZ {
  float y;
  float z;
};
#size: 2

struct ModelOutputEdgessXY {
  std::array<ModelOutputYZ, TRAJECTORY_SIZE> left;
  std::array<ModelOutputYZ, TRAJECTORY_SIZE> right;
};
#size: 2 * 33 * 2 = 132

struct ModelOutputRoadEdges {
  ModelOutputEdgessXY mean;
  ModelOutputEdgessXY std;
};
#size: 132 * 2 = 264
总结一下supercombo模型输出的ModelOutputRoadEdges，其包含左右两侧的道路边缘线，每条线有 33个2D坐标系的点，每个点分别有mean和std。这里虽然预测了车道线，但并不用于运动规划，只是在UI上显示，以及在车道偏离预警中使用。

ModelOutputRoadEdges 解析
ModelOutputRoadEdges 是 SuperCombo 模型输出的另一部分，专注于预测道路边缘线的位置和置信度。它涉及左右两侧的道路边缘线，类似于车道线，但不用于运动规划，而主要用于显示和车道偏离预警。

定义解析：
1. ModelOutputYZ
ModelOutputYZ 表示每个道路边缘线点的二维坐标，包含两个分量：y 和 z，即道路边缘线在 y-z 平面上的位置。

大小: 2（y 和 z 两个分量）。
2. ModelOutputEdgessXY
ModelOutputEdgessXY 表示左右道路边缘线在二维坐标系中的位置，它包含了两个数组，每个数组包含 33 个 ModelOutputYZ 类型的点（每个点由 y 和 z 坐标组成）。

left: 左侧道路边缘线。
right: 右侧道路边缘线。
每条道路边缘线有 33 个点，因此每条道路边缘线包含了 33 × 2 个数据（即 y 和 z 坐标）。

大小: 132（2 × 33 × 2）。
3. ModelOutputRoadEdges
ModelOutputRoadEdges 结构包含了道路边缘线的均值（mean）和标准差（std）信息。

mean: 道路边缘线的均值，表示道路边缘线位置的预测值。
std: 道路边缘线的标准差，表示道路边缘线位置的置信度的离散程度。
具体来说：

mean 和 std 都是 ModelOutputEdgessXY 结构，表示每条道路边缘线的均值和标准差（每条道路边缘线有 33 个点）。
大小：

mean 和 std: 每个是 132（2 × 33 × 2）。
因此，ModelOutputRoadEdges 总大小是：

264（mean 和 std 各 132）。
总结：
ModelOutputRoadEdges 预测了左右两侧的道路边缘线的位置信息。每条道路边缘线由 33 个点（y 和 z 坐标）表示，每个点的预测位置通过 均值（mean）和标准差（std） 进行描述。

该输出的主要用途是在 UI 显示 和 车道偏离预警 中，帮助驾驶员了解当前道路的边缘位置，以便及时作出反应。然而，尽管模型提供了道路边缘的预测数据，这些数据并不直接用于车辆的运动规划。

ModelOutputLeads的定义如下：
constexpr int LEAD_MHP_SELECTION = 3;
constexpr int LEAD_MHP_N = 2;
constexpr int LEAD_TRAJ_LEN = 6;


struct ModelOutputLeadElement {
  float x;
  float y;
  float velocity;
  float acceleration;
};
#size 4

struct ModelOutputLeadPrediction {
  std::array<ModelOutputLeadElement, LEAD_TRAJ_LEN> mean;
  std::array<ModelOutputLeadElement, LEAD_TRAJ_LEN> std;
  std::array<float, LEAD_MHP_SELECTION> prob;
};
#size: 4 * 6 * 2 + 3 = 51

struct ModelOutputLeads {
  std::array<ModelOutputLeadPrediction, LEAD_MHP_N> prediction;
  std::array<float, LEAD_MHP_SELECTION> prob;
}
#size: 51 * 2 + 3 = 102 + 3   这里分开写，是因为onnx里这里是2个输出的concat
总结一下supercombo模型输出的ModelOutputLeads：

首先，ModelOutputLeads.prob是一个数组，长度为LEAD_MHP_SELECTION（3），通过后续代码分析可知，这个数组的含义是模型判断后续0s，2s，4s时刻有leadcar在前方的置信度，不过这里的3个prob不是softmax计算后的情况，而是独立的，后续代码计算具体的置信度时会使用sigmoid(prob[i])这样的形式。可以推测，这个可以用已有的行车数据log进行回顾分析，当前时刻后续0s，2s，4s的acc毫米波雷达数据发现的leadcar信息对当前时刻的图像产生标注。为什么除了0s外，还要考虑2s和4s，推测是需要让模型能处理其他车辆cut in到当前车道的有能力预判。
其次，ModelOutputLeads.prediction也是一个数组，长度为LEAD_MHP_N（2），其包含前方可能的leadcar的预测信息，包括相对ego的位置xy和速度加速度，同时每个leadcar的信息会预测LEAD_TRAJ_LEN步，每个预测还有一个长度为LEAD_MHP_SELECTION（3）的prob表示置信度。通过后续代码分析可知，ModelOutputLeadPrediction.prediction.prob数组的含义是该预测在后续0s，2s，4s时刻为真的置信度。2个prediction互为冗余，例如，若要计算2s后的leadcar信息，则取2个prediction中prob[1]最大的那个。


ModelOutputLeads 解析
ModelOutputLeads 是 SuperCombo 模型的另一个输出部分，专注于预测与 ego vehicle（自车）在前方的其他车辆（lead car）的相对位置、速度和加速度。这个输出为后续的行为预测、路径规划以及碰撞预警提供信息。

定义解析：
1. ModelOutputLeadElement
ModelOutputLeadElement 表示一个预测的车辆（lead car）在某个时间点的状态，包括该车辆相对于自车的 x 和 y 位置、速度和加速度。

字段：
x: 该车辆在自车坐标系中的 x 坐标。
y: 该车辆在自车坐标系中的 y 坐标。
velocity: 该车辆的速度。
acceleration: 该车辆的加速度。
大小: 4（x, y, velocity, acceleration 各占 1 个浮点数）。
2. ModelOutputLeadPrediction
ModelOutputLeadPrediction 预测一个 lead car 在未来若干步（LEAD_TRAJ_LEN）的状态。每个预测包含：

mean: 预测的均值，即该车辆在未来若干步的平均位置、速度和加速度。
std: 预测的标准差，即该预测结果的不确定性。
prob: 一个长度为 LEAD_MHP_SELECTION（3）的数组，表示该预测在后续不同时间步（0s，2s，4s）为真的置信度。
大小：

mean 和 std：每个有 LEAD_TRAJ_LEN 步，且每步有 4 个浮点数（x, y, velocity, acceleration），所以是 4 × 6。
prob：一个长度为 3 的数组，表示置信度，大小为 3。
总大小为：

51（4 × 6 × 2 + 3）。
3. ModelOutputLeads
ModelOutputLeads 是整个结构的最外层，包含了多个 lead car 的预测数据。它包含：

prediction：一个长度为 LEAD_MHP_N（2）的数组，每个元素是一个 ModelOutputLeadPrediction，表示不同的 lead car 的预测数据。
prob：一个长度为 LEAD_MHP_SELECTION（3）的数组，表示不同时间步（0s，2s，4s）存在 lead car 的置信度。
大小：

prediction：包含 2 个 ModelOutputLeadPrediction，每个有大小 51，合计 102。
prob：长度为 3 的数组，大小为 3。
总大小为：

102 + 3 = 105。
总结：
ModelOutputLeads.prob：表示模型对于未来时间点（0s、2s、4s）是否会有 lead car 出现的置信度。这里的 prob 数组的 3 个值并不是 softmax 计算后的结果，而是独立的概率值（可能通过 sigmoid 函数转换）。这些数据与毫米波雷达等传感器数据结合，可以帮助模型理解当前时刻后续是否会有车辆进入自车车道，特别是对于可能发生的 cut-in（其他车辆切入）的情况。

ModelOutputLeads.prediction：表示模型对于前方可能的 2 个 lead car 的预测，包括它们在未来 LEAD_TRAJ_LEN 步内的相对位置（x, y）、速度和加速度。每个 lead car 的预测也包括它的置信度（通过 prob 数组表示）。在计算后续时间点的预测时，会选择置信度更高的预测作为最终结果（例如，如果要计算 2s 后的 lead car 信息，会选择两个 prediction 中 prob[1] 最大的一个）。

推测和用途：
这个输出数据可以帮助模型预判其他车辆的运动轨迹，尤其是在自车与其他车辆交互时（如切入车道时）。
ModelOutputLeads 为路径规划、碰撞预警和其他车道控制功能提供了重要的信息，通过融合其他传感器数据，提升自车的安全性和智能化程度。


ModelOutputMeta的定义如下：
constexpr int DISENGAGE_LEN = 5;
constexpr int BLINKER_LEN = 6;
constexpr int DESIRE_PRED_LEN = 4;
constexpr int DESIRE_LEN = 8;


struct ModelOutputDesireProb {
  union {
    struct {
      float none;
      float turn_left;
      float turn_right;
      float lane_change_left;
      float lane_change_right;
      float keep_left;
      float keep_right;
      float null;
    };
    struct {
      std::array<float, DESIRE_LEN> array;
    };
  };
};
#size: 8

struct ModelOutputDisengageProb {
  float gas_disengage;
  float brake_disengage;
  float steer_override;
  float brake_3ms2;
  float brake_4ms2;
  float brake_5ms2;
  float gas_pressed;
};
#size: 7

struct ModelOutputBlinkerProb {
  float left;
  float right;
};
#size 2

struct ModelOutputMeta {
  ModelOutputDesireProb desire_state_prob;
  float engaged_prob;
  std::array<ModelOutputDisengageProb, DISENGAGE_LEN> disengage_prob;
  std::array<ModelOutputBlinkerProb, BLINKER_LEN> blinker_prob;
  std::array<ModelOutputDesireProb, DESIRE_PRED_LEN> desire_pred_prob;
};
#size: 8 + (1 + 7*5 + 2*6) + 8*4 = 8 + 48 + 32   这里分开写，是因为onnx里这里是3个输出的concat
ModelOutputDisengageProb用于表示用户对ADAS的驾驶产生了脱离（disengage）操作，例如踩下了刹车且加速度达到
 。从后续代码的分析中可知，目前主要是刹车信息会用于前方碰撞警报FCW的判断，其他信息暂时没有用到。可以推测，这些脱离操作的概率，可以用已有的行车数据log进行回顾分析来生成标注数据。


 ModelOutputMeta 解析
ModelOutputMeta 是 SuperCombo 模型的一个输出部分，包含了有关驾驶员行为、ADAS 系统状态和驾驶需求预测等元数据。该输出有助于理解驾驶员的意图、车辆的状态以及驾驶模式，从而为路径规划、碰撞预警等系统提供支持。

定义解析：
1. ModelOutputDesireProb
ModelOutputDesireProb 表示驾驶员当前的意图或需求，这些需求通过多个可能的状态来表示，如转向、变道等。它通过 union 结构提供两种表示方式：

使用 结构体 显式列出每个需求的概率。
使用 数组 array 来表示所有需求的概率值。
字段：

none: 不做任何动作。
turn_left: 左转。
turn_right: 右转。
lane_change_left: 左变道。
lane_change_right: 右变道。
keep_left: 保持左侧车道。
keep_right: 保持右侧车道。
null: 空状态。
大小：

8（每个需求有一个浮点数表示其概率，共 8 个需求）。
2. ModelOutputDisengageProb
ModelOutputDisengageProb 用于表示驾驶员脱离驾驶辅助系统（ADAS）的操作，例如踩下刹车、加速踏板或启用转向覆盖（steer override）。这些脱离操作反映了驾驶员是否主动接管控制，尤其是在碰撞预警系统等触发时。

字段：

gas_disengage: 油门解除控制。
brake_disengage: 刹车解除控制。
steer_override: 转向覆盖。
brake_3ms2: 刹车加速度达到 3m/s²。
brake_4ms2: 刹车加速度达到 4m/s²。
brake_5ms2: 刹车加速度达到 5m/s²。
gas_pressed: 油门被踩下。
大小：

7（每个字段对应一个浮点数表示概率）。
3. ModelOutputBlinkerProb
ModelOutputBlinkerProb 表示车辆的转向灯（blinkers）状态，帮助判断车辆是否有变道或转弯的意图。

字段：

left: 左转向灯的概率。
right: 右转向灯的概率。
大小：

2（表示左右转向灯的概率）。
4. ModelOutputMeta
ModelOutputMeta 是最外层的结构，包含了多个元数据项，综合表示驾驶员当前的状态和需求，包括驾驶意图、ADAS 状态以及车辆的灯光状态等。

字段：

desire_state_prob: 一个 ModelOutputDesireProb 类型的结构，表示当前驾驶员的需求状态（如左转、右转等）。
engaged_prob: 表示车辆是否处于激活状态的概率。
disengage_prob: 一个长度为 DISENGAGE_LEN（5）的数组，表示驾驶员脱离 ADAS 系统的各项操作概率。
blinker_prob: 一个长度为 BLINKER_LEN（6）的数组，表示车辆的转向灯状态概率。
desire_pred_prob: 一个长度为 DESIRE_PRED_LEN（4）的数组，表示驾驶员未来需求的预测概率。
大小：

desire_state_prob：8（ModelOutputDesireProb 大小）。
engaged_prob：1（激活状态概率）。
disengage_prob：7（ModelOutputDisengageProb 大小）× 5（DISENGAGE_LEN）= 35。
blinker_prob：2（ModelOutputBlinkerProb 大小）× 6（BLINKER_LEN）= 12。
desire_pred_prob：8（ModelOutputDesireProb 大小）× 4（DESIRE_PRED_LEN）= 32。
总大小：

8 + 1 + 35 + 12 + 32 = 88。
总结：
ModelOutputMeta.desire_state_prob：表示当前时刻驾驶员的意图，例如是否打算转弯、变道等。
ModelOutputMeta.engaged_prob：表示车辆是否处于激活状态的概率，可能反映自动驾驶系统是否被启用。
ModelOutputMeta.disengage_prob：表示驾驶员脱离自动驾驶系统的操作概率，如踩下刹车、油门等。这些操作可能会触发碰撞预警系统（FCW）。从当前分析来看，主要使用刹车信息来进行碰撞预警。
ModelOutputMeta.blinker_prob：表示左右转向灯的状态，通常用于推测驾驶员是否准备变道或转弯。
ModelOutputMeta.desire_pred_prob：预测驾驶员未来一段时间内可能的需求。
推测和用途：
脱离操作（Disengage） 数据为碰撞预警系统（如前方碰撞警报）提供了触发条件。通过结合驾驶员的刹车、油门等操作，系统可以判断是否有潜在的危险情况。
驾驶员需求（Desire） 预测可以帮助车辆提前做出响应，例如准备变道、减速或加速。
转向灯（Blinker） 信息帮助系统判断驾驶员的意图，为路径规划和变道决策提供支持。
整体来看，ModelOutputMeta 提供了一个全面的驾驶员行为和车辆状态的预测框架，是实现高级驾驶辅助系统（ADAS）和自动驾驶系统的关键数据。


ModelOutputPose的定义如下：
struct ModelOutputXYZ {
  float x;
  float y;
  float z;
};
#size: 3

struct ModelOutputPose {
  ModelOutputXYZ velocity_mean;
  ModelOutputXYZ rotation_mean;
  ModelOutputXYZ velocity_std;
  ModelOutputXYZ rotation_std;
};
#size: 3 * 4 = 12
总结一下supercombo模型输出的ModelOutputPose，其包含当前车身姿态的速度与欧拉角的2个预测，每个预测有3个自由度，共6DoF，每个DoF预测值分别有mean和std。


ModelOutputPose 解析
ModelOutputPose 是 SuperCombo 模型的一个输出部分，包含了车辆当前姿态（包括速度和旋转）的预测数据。这些数据可以帮助车辆理解自己的当前运动状态（如位置、速度和姿势），对于路径规划、运动控制和状态监测等非常关键。

定义解析：
1. ModelOutputXYZ
ModelOutputXYZ 是一个简单的结构体，表示三维空间中的一个点或向量，通常用于表示车辆的速度、旋转等信息。每个字段对应车辆在 X、Y、Z 三个方向的分量。

字段：

x: 车辆在 X 轴方向的分量。
y: 车辆在 Y 轴方向的分量。
z: 车辆在 Z 轴方向的分量。
大小：

3（每个字段有一个浮点数表示坐标分量，共 3 个分量）。
2. ModelOutputPose
ModelOutputPose 用于表示车辆的当前姿态，包括其速度和旋转信息。它包含了两个部分的预测：

velocity_mean 和 velocity_std：分别表示车辆速度的均值和标准差。速度是一个三维向量，描述车辆在 X、Y 和 Z 方向上的运动。
rotation_mean 和 rotation_std：分别表示车辆旋转的均值和标准差。旋转通常通过欧拉角表示，描述车辆在三个轴上的旋转角度。
字段：

velocity_mean: 车辆速度的均值（包括 X、Y、Z 方向）。
rotation_mean: 车辆旋转的均值（欧拉角，描述绕 X、Y、Z 轴的旋转）。
velocity_std: 车辆速度的标准差（同样在 X、Y、Z 方向）。
rotation_std: 车辆旋转的标准差（同样在 X、Y、Z 方向）。
大小：

每个 ModelOutputXYZ 包含 3 个字段（x、y、z），因此每个结构体的大小为 3。
ModelOutputPose 包含 4 个 ModelOutputXYZ 结构体，因此总大小为 3 * 4 = 12。
总结：
ModelOutputPose 包含了车辆姿态的速度和旋转预测信息，每个预测值都有均值（mean）和标准差（std）。具体来说：

速度预测：车辆在三维空间中的速度预测，包括在 X、Y、Z 方向的速度值，以及对应的标准差，用于描述速度的不确定性。
旋转预测：车辆的旋转角度预测，通常通过欧拉角表示，涵盖车辆绕 X、Y 和 Z 轴的旋转角度，以及相应的标准差，用于描述旋转的不确定性。
用途：
速度和旋转预测：这为车辆提供了关于其当前运动状态的重要信息，能够帮助进行精确的路径规划和控制。
标准差（std）：表示这些预测的不确定性，有助于系统评估当前状态的可靠性，并作出相应的调整。
6自由度（6DoF）：模型预测了车辆的 6DoF 运动，包括位置（通过速度）和旋转（通过欧拉角），这些信息对于车辆定位和姿态控制至关重要。
总大小：
12（ModelOutputPose 的总大小为 12）。

ModelOutputWideFromDeviceEulers的定义如下：
struct ModelOutputXYZ {
  float x;
  float y;
  float z;
};
#size: 3

struct ModelOutputWideFromDeviceEuler {
  ModelOutputXYZ mean;
  ModelOutputXYZ std;
};
#size: 3*2 = 6
总结一下supercombo模型输出的ModelOutputWideFromDeviceEuler，其提供了comma设备挂在前风挡上的欧拉角（相机外参）的估计，3个欧拉角分别各自有mean和std。

ModelOutputPose和ModelOutputWideFromDeviceEuler，在openpilot代码中，属于posenet，其预测值被合并后通过 cameraOdometry 事件通知给校准模块进行处理，用于计算相机图像在推理前的校准变换。

ModelOutputTemporalPose的定义如下：
struct ModelOutputXYZ {
  float x;
  float y;
  float z;
};
#size: 3

struct ModelOutputTemporalPose {
  ModelOutputXYZ velocity_mean;
  ModelOutputXYZ rotation_mean;
  ModelOutputXYZ velocity_std;
  ModelOutputXYZ rotation_std;
};

#size: 3*4 = 12
ModelOutputTemporalPose与ModelOutputPose的内容一样，但其不属于posenet，其输出值会和supercombo大部分输出值一起封装到modelV2消息里交给规划模块进行使用。

ModelOutputWideFromDeviceEuler 解析
ModelOutputWideFromDeviceEuler 是 SuperCombo 模型的一部分，它用于提供挂在车辆前风挡上的设备（例如相机）外参（即欧拉角）的估计。对于每个欧拉角，模型提供了均值（mean）和标准差（std）这两个值。欧拉角通常用于描述三维空间中的旋转，通过三个角度（例如俯仰角、偏航角和滚转角）来定义。

定义解析：
1. ModelOutputXYZ
ModelOutputXYZ 表示三维空间中的一个点或向量，通常用于表示欧拉角的每个分量。每个字段对应一个坐标轴上的旋转分量。

字段：

x: 对应第一个欧拉角的分量。
y: 对应第二个欧拉角的分量。
z: 对应第三个欧拉角的分量。
大小：

3（每个字段有一个浮点数表示欧拉角分量，共 3 个分量）。
2. ModelOutputWideFromDeviceEuler
ModelOutputWideFromDeviceEuler 结构体用于表示从设备（如相机）挂载在车辆前风挡上获取的旋转估计值。它包含：

mean: 表示欧拉角的均值（即旋转角度的期望值）。
std: 表示欧拉角的标准差，用于描述旋转角度的预测不确定性。
字段：

mean: 设备的欧拉角估计的均值。
std: 设备的欧拉角估计的标准差。
大小：

每个 ModelOutputXYZ 包含 3 个字段（x、y、z），因此每个 ModelOutputWideFromDeviceEuler 的大小为 6（mean 和 std 各占 3 个字段，总共 6 个字段）。
总结：
ModelOutputWideFromDeviceEuler 提供了挂在车辆前风挡上的设备（例如相机）外参（即欧拉角）的估计信息。模型输出了每个欧拉角的均值（mean）和标准差（std）。这些输出有助于理解相机或其他设备的姿态估计，确保图像数据能够正确地与车辆的世界坐标系对齐。

欧拉角：通过三个角度（通常是俯仰角、偏航角和滚转角）表示设备的旋转状态。
标准差：表示欧拉角预测的不确定性，帮助系统评估该估计值的可靠性。
用途：
校准变换：ModelOutputWideFromDeviceEuler 提供的欧拉角估计可以帮助在推理前进行相机图像的校准变换。这对于确保图像与车辆的实际位置和姿态一致至关重要。
位置与姿态计算：这些信息有助于规划模块和其他系统了解当前设备（如相机）的朝向，从而提供更精确的预测。
ModelOutputPose 与 ModelOutputWideFromDeviceEuler 的关系：
ModelOutputPose 和 ModelOutputWideFromDeviceEuler 都与车辆的姿态和运动状态密切相关。尽管它们的输出类型相似（都包含速度和旋转的均值与标准差），它们用于不同的模块：

ModelOutputPose 主要用于车辆的 posenet，处理车辆的6自由度（6DoF）运动预测。
ModelOutputWideFromDeviceEuler 提供相机或其他设备的外参估计，主要用于图像校准，在 cameraOdometry 事件中与其他输出一起传递给校准模块。
这两个输出通过合并的方式为系统提供了关于车辆和设备相对世界坐标系的完整信息，确保在进行路径规划和运动控制时的精准度。

ModelOutputTemporalPose 解析
ModelOutputTemporalPose 与 ModelOutputPose 很相似，但它们的输出方式有所不同，且不属于 posenet 模块。ModelOutputTemporalPose 用于提供车辆的动态状态，包括速度和旋转的均值与标准差。它的输出值会与大部分其他输出一起封装到 modelV2 消息中，并被传递给规划模块使用。

定义解析：
ModelOutputTemporalPose 的结构与 ModelOutputPose 一致，包含速度和旋转的均值（mean）和标准差（std）：

velocity_mean 和 velocity_std：表示车辆速度在 X、Y、Z 方向上的均值和标准差。
rotation_mean 和 rotation_std：表示车辆旋转角度（欧拉角）的均值和标准差。
大小：

12（与 ModelOutputPose 相同，3 * 4 = 12）。
总结：
ModelOutputTemporalPose 和 ModelOutputPose 相似，都是描述车辆的速度和旋转状态，包含三维空间中的各个方向的预测信息。
不同之处在于 ModelOutputTemporalPose 不属于 posenet，并且它的输出将与其他输出一同传递给规划模块，参与路径规划和决策。
总大小：
ModelOutputWideFromDeviceEuler：6（由 2 个 ModelOutputXYZ 组成，每个大小为 3，总共为 6）。
ModelOutputPose 和 ModelOutputTemporalPose：12（由 4 个 ModelOutputXYZ 组成，每个大小为 3，总共为 12）。
这两个输出结构体在模型中都起到了至关重要的作用，为后续的路径规划、决策与控制模块提供了基础的车辆动态与姿态信息。



Nav 模型输入与输出解析
Nav 模型主要用于从导航产生的图像中提取特征，这些特征随后被传递给 SuperCombo 模型进行进一步处理。

输入：
图像：Nav 模型的输入是导航系统生成的图像。这些图像可能包含车辆周围环境的视觉信息，例如路面、交通标志、其他车辆等。
输出：
nav_features：Nav 模型的输出是一个特征向量，形状为 1x64，即输出是一个 64 维的向量。这个向量包含从输入图像中提取的特征信息，用于传递给 SuperCombo 模型。
详细说明：
输入图像：通常，导航系统会使用车载相机或其他传感器来捕获周围环境的图像，这些图像会包含道路信息、障碍物、交通标志、车道线等。Nav 模型会处理这些图像并提取出有助于后续决策和预测的特征。

nav_features 输出：nav_features 是 Nav 模型生成的特征向量，形状为 1x64，表示从图像中提取的 64 维特征。这些特征可以是图像的高层次信息，如场景的整体布局、道路的形态、可识别的标志或其他动态元素等。这个输出向量将作为输入，传递给 SuperCombo 模型，用于进一步的分析和预测。

如何使用 nav_features：
nav_features 会作为 SuperCombo 模型的输入之一，帮助 SuperCombo 更好地理解当前的车辆环境，并作出准确的预测。这些特征可以帮助 SuperCombo 预测与车辆运动、交通情况、碰撞预警等相关的信息。

总结：
输入：Nav 模型的输入是导航图像，可能来自车载相机或其他传感器。
输出：Nav 模型输出的是一个 64 维的特征向量 nav_features，用于给 SuperCombo 模型提供进一步分析的基础。
通过这种方式，Nav 模型帮助从图像中提取出关键特征，辅助 SuperCombo 进行更精确的车辆控制和决策。

constexpr int NAV_FEATURE_LEN = 64;

struct NavModelOutputFeatures {
  std::array<float, NAV_FEATURE_LEN> values;
};

struct NavModelResult {
  const NavModelOutputPlan plan;                      #目前是空值，无用
  const NavModelOutputDesirePrediction desire_pred;   #目前是空值，无用
  const NavModelOutputFeatures features;              #有用
  float dsp_execution_time;
};


NavModelResult 结构体解析
NavModelResult 是 Nav 模型的输出结构体，包含多个字段，其中 features 是实际有用的部分，表示模型从输入的导航图像中提取的特征信息。下面是对各个字段的详细解析：

结构定义：
cpp
复制
编辑
constexpr int NAV_FEATURE_LEN = 64;

struct NavModelOutputFeatures {
  std::array<float, NAV_FEATURE_LEN> values;  // 长度为 64 的特征向量
};

struct NavModelResult {
  const NavModelOutputPlan plan;               // 目前为空，无用
  const NavModelOutputDesirePrediction desire_pred;  // 目前为空，无用
  const NavModelOutputFeatures features;       // 实际有用，64 维的特征向量
  float dsp_execution_time;                    // 执行时间（单位：秒）
};
字段解析：
NavModelOutputFeatures features：

类型：NavModelOutputFeatures
描述：该字段包含一个长度为 64 的特征向量 (std::array<float, NAV_FEATURE_LEN>)，由 Nav 模型从导航图像中提取出来的特征。这个特征向量包含了有关当前图像（例如，路面状况、交通标志、车道线、周围物体等）的关键信息，供后续的 SuperCombo 模型使用。
NavModelOutputPlan plan：

类型：NavModelOutputPlan
描述：这个字段目前是空值，并没有实际的用途。通常，这种字段可能是为将来扩展而预留的，用于存储与导航相关的计划信息。
NavModelOutputDesirePrediction desire_pred：

类型：NavModelOutputDesirePrediction
描述：该字段目前也为空，没有实际用途。一般来说，这个字段可能会用于存储与驾驶意图（例如：车辆的转向、加速等）相关的预测结果。
float dsp_execution_time：

类型：float
描述：这个字段记录了模型执行的时间，单位通常为秒。这有助于分析模型的性能，了解在给定的计算资源下，生成特征的时间消耗。
总结：
features 是 NavModelResult 中唯一有用的字段，包含了长度为 64 的特征向量，代表从导航图像中提取的重要特征。
plan 和 desire_pred 当前为空，暂时无用，可能是为将来的扩展预留的字段。
dsp_execution_time 用于记录模型推理的执行时间。
通过这个结构体，Nav 模型能够输出图像特征、执行时间等信息，供后续的模型（如 SuperCombo）进一步使用。

Driver Monitoring 模型
该模型使用comma设备的前置广角摄像头，判断拍摄驾驶员状态，防止他没有将注意力放在前方道路上。若判定驾驶员注意力问题则会警示或退出辅助驾驶状态。

数据输入格式：

single image (640 * 320 * 3 in RGB):
full input size is 6 * 640/2 * 320/2 = 307200
represented in YUV420 with 6 channels:
Channels 0,1,2,3 represent the full-res Y channel and are represented in numpy as Y[::2, ::2], Y[::2, 1::2], Y[1::2, ::2], and Y[1::2, 1::2]
Channel 4 represents the half-res U channel
Channel 5 represents the half-res V channel
normalized, ranging from -1.0 to 1.0
数据输出格式：

39 x float32 outputs
face pose: 12 = 6 + 6
face orientation [pitch, yaw, roll] in camera frame: 3
face position [dx, dy] relative to image center: 2
normalized face size: 1
standard deviations for above outputs: 6
face visible probability: 1
eyes: 20 = (8 + 1) + (8 + 1) + 1 + 1
eye position and size, and their standard deviations: 8
eye visible probability: 1
eye closed probability: 1
wearing sunglasses probability: 1
poor camera vision probability: 1
face partially out-of-frame probability: 1
(deprecated) distracted probabilities: 2
face covered probability: 1


Driver Monitoring 模型输出格式解析
Driver Monitoring 模型用于从前置广角摄像头图像中判断驾驶员的状态，主要目的是确保驾驶员的注意力集中在道路上。该模型分析图像后输出一系列的指标，帮助判断驾驶员的状态是否符合驾驶安全要求。

输入数据格式：
输入数据是由摄像头捕获的图像，大小为 640x320，RGB 格式的三通道图像（每个像素有红、绿、蓝三个通道），总像素数量为：

输入图像尺寸：640 * 320 * 3 = 614,400 字节
输入格式：YUV420 编码，6 个通道：
通道 0, 1, 2, 3：表示全分辨率的 Y 通道（Y[::2, ::2]、Y[::2, 1::2]、Y[1::2, ::2] 和 Y[1::2, 1::2]），每个通道的尺寸为 640x320 的 1/2 解析度。
通道 4：半分辨率的 U 通道
通道 5：半分辨率的 V 通道
归一化范围：输入值在 -1.0 到 1.0 之间
输出数据格式：
输出数据包含多个浮点值，表示不同的驾驶员状态预测。以下是各个输出字段的具体含义和维度：

Face Pose（12 个浮点值）：

6 个浮点值：面部位置和大小相关的标准偏差。
6 个浮点值：面部姿态（包括 pitch、yaw、roll）相关的标准偏差。
Face Orientation（3 个浮点值）：

面部在相机坐标系中的姿态（pitch、yaw、roll）。
Face Position（2 个浮点值）：

面部相对图像中心的位置（dx, dy）。
Normalized Face Size（1 个浮点值）：

归一化的面部大小。
Standard Deviations for Above Outputs（6 个浮点值）：

上述面部姿态、位置和大小输出的标准偏差。
Face Visible Probability（1 个浮点值）：

面部是否可见的概率。
Eyes（20 个浮点值）：

眼睛位置和大小：
8 个浮点值：每只眼睛的眼睛位置和大小（左右眼各 8 个值）。
2 个浮点值：每只眼睛的标准偏差。
眼睛是否可见的概率（1 个浮点值）
眼睛闭合的概率（1 个浮点值）
Additional Information（5 个浮点值）：

佩戴太阳镜的概率（1 个浮点值）
摄像头视野不清的概率（1 个浮点值）
面部部分离开框架的概率（1 个浮点值）
Deprecated Distracted Probabilities（2 个浮点值）：

已废弃的分心驾驶概率值，过去用于表示驾驶员是否分心，但此部分数据已经不再使用。
Face Covered Probability（1 个浮点值）：

面部是否被遮挡的概率。
总结：
该模型的输出主要涉及面部及眼睛的各种状态信息，包括姿态（pitch, yaw, roll）、位置（dx, dy）、大小（normalized size）、可见性、眼睛状态等。通过这些信息，系统可以检测到驾驶员是否注意力集中，例如，是否闭眼、是否佩戴太阳镜、是否面部被遮挡等。

此外，面部遮挡、视野不清等信息也可以用来判断摄像头是否处于异常状态，从而进一步提升驾驶辅助系统的安全性。
